{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T09:49:33.798966Z",
     "iopub.status.busy": "2024-02-24T09:49:33.798426Z",
     "iopub.status.idle": "2024-02-24T09:49:36.073819Z",
     "shell.execute_reply": "2024-02-24T09:49:36.072631Z",
     "shell.execute_reply.started": "2024-02-24T09:49:33.798932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/higgs-spring-2024/sample_submission.csv.zip\n",
      "/kaggle/input/higgs-spring-2024/test.csv\n",
      "/kaggle/input/higgs-spring-2024/train.csv.zip\n",
      "/kaggle/input/higgs-spring-2024/sample_submission.csv\n",
      "/kaggle/input/higgs-spring-2024/train.csv\n",
      "/kaggle/input/higgs-spring-2024/test.csv.zip\n"
     ]
    }
   ],
   "source": [
    "''' Train GaussianNB model on HIGGS classification problem and submit to competition.\n",
    "Author: Peter Sadowski\n",
    "Date: Feb 12 2024\n",
    "'''\n",
    "import ast\n",
    "import numpy as np \n",
    "import matplotlib.pylab as plt \n",
    "import sklearn \n",
    "import sklearn.metrics \n",
    "\n",
    "from joblib import dump\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, ParameterGrid\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "data = np.loadtxt('/kaggle/input/higgs-spring-2024/train.csv', skiprows=1, delimiter=',')\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iNhuvq0SHqmC"
   },
   "source": [
    "# Train and Assess Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T02:57:16.619241Z",
     "iopub.status.busy": "2024-02-13T02:57:16.618769Z",
     "iopub.status.idle": "2024-02-13T02:57:16.626175Z",
     "shell.execute_reply": "2024-02-13T02:57:16.624985Z",
     "shell.execute_reply.started": "2024-02-13T02:57:16.6192Z"
    },
    "id": "YdrQBcFm_TFw"
   },
   "outputs": [],
   "source": [
    "# Split off validation set for testing.\n",
    "Xtrain = data[:40000, 1:]\n",
    "Ytrain = data[:40000, 0:1]\n",
    "Xvalid = data[40000:, 1:]\n",
    "Yvalid = data[40000:, 0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T03:00:54.314512Z",
     "iopub.status.busy": "2024-02-13T03:00:54.314111Z",
     "iopub.status.idle": "2024-02-13T03:00:54.570979Z",
     "shell.execute_reply": "2024-02-13T03:00:54.569687Z",
     "shell.execute_reply.started": "2024-02-13T03:00:54.314481Z"
    },
    "id": "g7YlDbLP_rtx",
    "outputId": "bc4a72b0-9952-4091-cab9-7f3445a643df",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searching\n",
      "Skipping:   15 /  6336\n",
      "Evaluating: 19 / 6336\n",
      "Skipping:   30 /  6336\n",
      "Evaluating: 41 / 6336\n",
      "Evaluating: 45 / 6336\n",
      "Evaluating: 46 / 6336\n",
      "Evaluating: 47 / 6336\n",
      "Evaluating: 48 / 6336\n",
      "Evaluating: 49 / 6336\n",
      "Evaluating: 50 / 6336\n",
      "Evaluating: 51 / 6336\n",
      "Evaluating: 52 / 6336\n",
      "Evaluating: 53 / 6336\n",
      "Evaluating: 54 / 6336\n",
      "Evaluating: 55 / 6336\n",
      "Evaluating: 56 / 6336\n",
      "Evaluating: 57 / 6336\n",
      "Evaluating: 58 / 6336\n",
      "Evaluating: 59 / 6336\n",
      "Evaluating: 60 / 6336\n",
      "Evaluating: 61 / 6336\n",
      "Evaluating: 62 / 6336\n",
      "Evaluating: 63 / 6336\n",
      "Evaluating: 64 / 6336\n",
      "Evaluating: 65 / 6336\n",
      "Evaluating: 66 / 6336\n",
      "Skipping:   75 /  6336\n",
      "Evaluating: 85 / 6336\n",
      "Skipping:   90 /  6336\n",
      "Skipping:  105 /  6336\n",
      "Evaluating: 107 / 6336\n",
      "Skipping:  120 /  6336\n",
      "Evaluating: 129 / 6336\n",
      "Skipping:  135 /  6336\n",
      "Skipping:  150 /  6336\n",
      "Evaluating: 151 / 6336\n",
      "Skipping:  165 /  6336\n",
      "Evaluating: 173 / 6336\n",
      "Evaluating: 177 / 6336\n",
      "Evaluating: 178 / 6336\n",
      "Evaluating: 179 / 6336\n",
      "Evaluating: 180 / 6336\n",
      "Evaluating: 181 / 6336\n",
      "Evaluating: 182 / 6336\n",
      "Evaluating: 183 / 6336\n",
      "Evaluating: 184 / 6336\n",
      "Evaluating: 185 / 6336\n",
      "Evaluating: 186 / 6336\n",
      "Evaluating: 187 / 6336\n",
      "Evaluating: 188 / 6336\n",
      "Evaluating: 189 / 6336\n",
      "Evaluating: 190 / 6336\n",
      "Evaluating: 191 / 6336\n",
      "Evaluating: 192 / 6336\n",
      "Evaluating: 193 / 6336\n",
      "Evaluating: 194 / 6336\n",
      "Evaluating: 195 / 6336\n",
      "Evaluating: 196 / 6336\n",
      "Evaluating: 197 / 6336\n",
      "Evaluating: 198 / 6336\n",
      "Skipping:  210 /  6336\n",
      "Evaluating: 217 / 6336\n",
      "Skipping:  225 /  6336\n",
      "Evaluating: 239 / 6336\n",
      "Skipping:  240 /  6336\n",
      "Skipping:  255 /  6336\n",
      "Evaluating: 261 / 6336\n",
      "Skipping:  270 /  6336\n",
      "Evaluating: 283 / 6336\n",
      "Skipping:  285 /  6336\n",
      "Skipping:  300 /  6336\n",
      "Evaluating: 305 / 6336\n",
      "Evaluating: 309 / 6336\n",
      "Evaluating: 310 / 6336\n",
      "Evaluating: 311 / 6336\n",
      "Evaluating: 312 / 6336\n",
      "Evaluating: 313 / 6336\n",
      "Evaluating: 314 / 6336\n",
      "Evaluating: 315 / 6336\n",
      "Evaluating: 316 / 6336\n",
      "Evaluating: 317 / 6336\n",
      "Evaluating: 318 / 6336\n",
      "Evaluating: 319 / 6336\n",
      "Evaluating: 320 / 6336\n",
      "Evaluating: 321 / 6336\n",
      "Evaluating: 322 / 6336\n",
      "Evaluating: 323 / 6336\n",
      "Evaluating: 324 / 6336\n",
      "Evaluating: 325 / 6336\n",
      "Evaluating: 326 / 6336\n",
      "Evaluating: 327 / 6336\n",
      "Evaluating: 328 / 6336\n",
      "Evaluating: 329 / 6336\n",
      "Evaluating: 330 / 6336\n",
      "Skipping:  345 /  6336\n",
      "Evaluating: 349 / 6336\n",
      "Skipping:  360 /  6336\n",
      "Evaluating: 371 / 6336\n",
      "Skipping:  375 /  6336\n",
      "Skipping:  390 /  6336\n",
      "Evaluating: 393 / 6336\n",
      "Skipping:  405 /  6336\n",
      "Evaluating: 415 / 6336\n",
      "Skipping:  420 /  6336\n",
      "Skipping:  435 /  6336\n",
      "Evaluating: 437 / 6336\n",
      "Evaluating: 441 / 6336\n",
      "Evaluating: 442 / 6336\n",
      "Evaluating: 443 / 6336\n",
      "Evaluating: 444 / 6336\n",
      "Evaluating: 445 / 6336\n",
      "Evaluating: 446 / 6336\n",
      "Evaluating: 447 / 6336\n",
      "Evaluating: 448 / 6336\n",
      "Evaluating: 449 / 6336\n",
      "Evaluating: 450 / 6336\n",
      "Evaluating: 451 / 6336\n",
      "Evaluating: 452 / 6336\n",
      "Evaluating: 453 / 6336\n",
      "Evaluating: 454 / 6336\n",
      "Evaluating: 455 / 6336\n",
      "Evaluating: 456 / 6336\n",
      "Evaluating: 457 / 6336\n",
      "Evaluating: 458 / 6336\n",
      "Evaluating: 459 / 6336\n",
      "Evaluating: 460 / 6336\n",
      "Evaluating: 461 / 6336\n",
      "Evaluating: 462 / 6336\n",
      "Skipping:  465 /  6336\n",
      "Skipping:  480 /  6336\n",
      "Evaluating: 481 / 6336\n",
      "Skipping:  495 /  6336\n",
      "Evaluating: 503 / 6336\n",
      "Skipping:  510 /  6336\n",
      "Evaluating: 525 / 6336\n",
      "Skipping:  540 /  6336\n",
      "Evaluating: 547 / 6336\n",
      "Skipping:  555 /  6336\n",
      "Evaluating: 569 / 6336\n",
      "Skipping:  570 /  6336\n",
      "Evaluating: 573 / 6336\n",
      "Evaluating: 574 / 6336\n",
      "Evaluating: 575 / 6336\n",
      "Evaluating: 576 / 6336\n",
      "Evaluating: 577 / 6336\n",
      "Evaluating: 578 / 6336\n",
      "Evaluating: 579 / 6336\n",
      "Evaluating: 580 / 6336\n",
      "Evaluating: 581 / 6336\n",
      "Evaluating: 582 / 6336\n",
      "Evaluating: 583 / 6336\n",
      "Evaluating: 584 / 6336\n",
      "Evaluating: 585 / 6336\n",
      "Evaluating: 586 / 6336\n",
      "Evaluating: 587 / 6336\n",
      "Evaluating: 588 / 6336\n",
      "Evaluating: 589 / 6336\n",
      "Evaluating: 590 / 6336\n",
      "Evaluating: 591 / 6336\n",
      "Evaluating: 592 / 6336\n",
      "Evaluating: 593 / 6336\n",
      "Evaluating: 594 / 6336\n",
      "Skipping:  600 /  6336\n",
      "Evaluating: 613 / 6336\n",
      "Skipping:  615 /  6336\n",
      "Skipping:  630 /  6336\n",
      "Evaluating: 635 / 6336\n",
      "Skipping:  645 /  6336\n",
      "Evaluating: 657 / 6336\n",
      "Skipping:  660 /  6336\n",
      "Skipping:  675 /  6336\n",
      "Evaluating: 679 / 6336\n",
      "Skipping:  690 /  6336\n",
      "Evaluating: 701 / 6336\n",
      "Evaluating: 705 / 6336\n",
      "Evaluating: 706 / 6336\n",
      "Evaluating: 707 / 6336\n",
      "Evaluating: 708 / 6336\n",
      "Evaluating: 709 / 6336\n",
      "Evaluating: 710 / 6336\n",
      "Evaluating: 711 / 6336\n",
      "Evaluating: 712 / 6336\n",
      "Evaluating: 713 / 6336\n",
      "Evaluating: 714 / 6336\n",
      "Evaluating: 715 / 6336\n",
      "Evaluating: 716 / 6336\n",
      "Evaluating: 717 / 6336\n",
      "Evaluating: 718 / 6336\n",
      "Evaluating: 719 / 6336\n",
      "Evaluating: 720 / 6336\n",
      "Evaluating: 721 / 6336\n",
      "Evaluating: 722 / 6336\n",
      "Evaluating: 723 / 6336\n",
      "Evaluating: 724 / 6336\n",
      "Evaluating: 725 / 6336\n",
      "Evaluating: 726 / 6336\n",
      "Skipping:  735 /  6336\n",
      "Evaluating: 745 / 6336\n",
      "Skipping:  750 /  6336\n",
      "Skipping:  765 /  6336\n",
      "Evaluating: 767 / 6336\n",
      "Skipping:  780 /  6336\n",
      "Evaluating: 789 / 6336\n",
      "Skipping:  795 /  6336\n",
      "Skipping:  810 /  6336\n",
      "Evaluating: 811 / 6336\n",
      "Skipping:  825 /  6336\n",
      "Evaluating: 833 / 6336\n",
      "Evaluating: 837 / 6336\n",
      "Evaluating: 838 / 6336\n",
      "Evaluating: 839 / 6336\n",
      "Evaluating: 840 / 6336\n",
      "Evaluating: 841 / 6336\n",
      "Evaluating: 842 / 6336\n",
      "Evaluating: 843 / 6336\n",
      "Evaluating: 844 / 6336\n",
      "Evaluating: 845 / 6336\n",
      "Evaluating: 846 / 6336\n",
      "Evaluating: 847 / 6336\n",
      "Evaluating: 848 / 6336\n",
      "Evaluating: 849 / 6336\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_73654/751751405.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mresults_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mresults_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"roc_auc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"grid_search_results.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_73654/751751405.py\u001b[0m in \u001b[0;36mgrid_search\u001b[0;34m(model, parameters, cv, scoring, results_path)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Evaluating: {c} / {N}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mauroc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYvalid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1349\u001b[0m                 )\n\u001b[1;32m   1350\u001b[0m             ):\n\u001b[0;32m-> 1351\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    490\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         )\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1950\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1952\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1705\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1706\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1708\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit model to train.\n",
    "var_smoothing_range = np.logspace(-10, -7, 20)\n",
    "AUROC = []\n",
    "\n",
    "var_smoothing = var_smoothing_range[0]\n",
    "model = GaussianNB(var_smoothing=var_smoothing)\n",
    "model.fit(Xtrain, Ytrain.flatten())\n",
    "\n",
    "# parameters = {\n",
    "#     \"n_estimators\": [100, 200],\n",
    "#     \"max_depth\": [None, 10, 20],\n",
    "#     \"min_samples_split\": [2,5],\n",
    "#     \"min_samples_leaf\": [1,2]\n",
    "# }\n",
    "parameters = {\n",
    "    \"n_estimators\": [1,2,3,4,5,6,7,8,10,100,200,300,400,500,600,650,675,700,715,725,750,800],  # Only one option\n",
    "    \"max_depth\": [1,2,3,4,5,6,10,20,23,24,25,26,27,28,30, None],    # Only one option\n",
    "    \"min_samples_split\": [2,3,4,5,7,10],  # Only one option\n",
    "    \"min_samples_leaf\": [1,2,3],  # Only one option\n",
    "    \"n_jobs\": [-1],\n",
    "    \"random_state\": [42]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(Xtrain, Ytrain.flatten())\n",
    "\n",
    "print(\"searching\")\n",
    "def grid_search(model, parameters, cv=5, scoring=\"roc_auc\", results_path=\"grid_search_results.csv\"):\n",
    "    results_df = None\n",
    "    if os.path.exists(results_path):\n",
    "        results_df = pd.read_csv(results_path)\n",
    "    else:\n",
    "        results_df = pd.DataFrame(columns=[\"params\", \"score\"])\n",
    "    N = len(list(ParameterGrid(parameters)))\n",
    "    c = 0\n",
    "    for params in ParameterGrid(parameters):\n",
    "        c += 1\n",
    "        if not any(results_df[\"params\"] == str(params)):\n",
    "            print(f\"Evaluating: {c:5} / {N}\")\n",
    "            model.set_params(**params)\n",
    "            model.fit(Xtrain, Ytrain.flatten())\n",
    "            predictions = model.predict_proba(Xvalid)\n",
    "            auroc = sklearn.metrics.roc_auc_score(Yvalid[:,0], predictions[:,1])\n",
    "            row = pd.DataFrame({\"params\": [str(params)], \"score\": [auroc]})\n",
    "            results_df = pd.concat([results_df, row], ignore_index=True)\n",
    "            results_df.to_csv(results_path, index=False)\n",
    "        elif (c % 15 == 0) or (c == N):\n",
    "            print(f\"Skipping: {c:5} / {N:5}\")\n",
    "    results_df.sort_values(by=\"score\", ascending=False)\n",
    "    results_df.to_csv(results_path, index=False)\n",
    "    return results_df\n",
    "results_df = grid_search(rf, parameters, cv=5, scoring=\"roc_auc\", results_path=\"grid_search_results.csv\")\n",
    "i = results_df[\"score\"].idxmax()\n",
    "row = results_df.loc[i]\n",
    "params_string = row[\"params\"]\n",
    "params = ast.literal_eval(params_string)\n",
    "print(\"Results shape:\", results_df.shape)\n",
    "print(params, row[\"score\"])\n",
    "\n",
    "rf.set_params(**params)\n",
    "rf.fit(Xtrain, Ytrain.flatten())\n",
    "      \n",
    "ensemble = VotingClassifer(estimators=[('nb', nb), (\"rf\", rf)], voting=\"soft\")\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "#     grid_search = GridSearchCV(RandomForestClassifier(), parameters, cv=5, scoring=\"roc_auc\", verbose=2)\n",
    "#     grid_search.fit(Xtrain, Ytrain.flatten())\n",
    "#     dump(grid_search, \"grid_search_results.joblib\")\n",
    "\n",
    "# Make hard predictions.\n",
    "hard_predictions = model.predict(Xvalid)\n",
    "\n",
    "# Make probabilistic predictions.\n",
    "predictions = model.predict_proba(Xvalid)\n",
    "rf_predictions = rf.predict_proba(Xvalid)\n",
    "predictions_ensemble = ensemble.predict_proba(Xvalid)\n",
    "\n",
    "# Compute AUROC.\n",
    "val = sklearn.metrics.roc_auc_score(Yvalid[:,0], predictions[:,1])\n",
    "rf_auroc = sklearn.metrics.roc_auc_score(Yvalid[:,0], rf_predictions[:,1])\n",
    "auroc_ensemble = sklearn.metrics.roc_auc_score(Yvalid[:,0], rf_predictions[:,1])\n",
    "print(f'Validation AUROC: {val}, {rf_auroc}, {auroc_ensemble} ' )\n",
    "\n",
    "# Plot ROC curve.\n",
    "fpr, tpr, thresholds = sklearn.metrics.roc_curve(Yvalid[:,0], predictions[:,1])\n",
    "fpr_rf, tpr_rf, thesholds_rf = sklearn.metrics.roc_curve(Yvalid[:,0], rf_predictions[:,1])\n",
    "fpr_ensemble, tpr_ensemble, thresholds_ensemble = sklearn.metrics.roc_curve(Yvalid[:,0], predictions_ensemble[:,1])\n",
    "plt.plot(fpr, tpr, label=\"Naive Bayes\")\n",
    "plt.plot(fpr_rf, tpr_rf, \"Random Forest\")\n",
    "plt.plot(fpr_ensemble, tpr_ensemble, \"Ensemble\")\n",
    "plt.plot([0, 1], [0, 1], color='k', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(frameon=False, fontsize=\"small\", title=\"Legend Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T02:57:16.899418Z",
     "iopub.status.busy": "2024-02-13T02:57:16.899037Z",
     "iopub.status.idle": "2024-02-13T02:57:17.862184Z",
     "shell.execute_reply": "2024-02-13T02:57:17.861039Z",
     "shell.execute_reply.started": "2024-02-13T02:57:16.899383Z"
    },
    "id": "rV80OJTm_LpF",
    "outputId": "8908bde0-c69f-42a0-c8a2-eed321ee95f8"
   },
   "outputs": [],
   "source": [
    "results_df = results_df.sort_values(by=\"score\", ascending=False)\n",
    "print(results_df)\n",
    "\n",
    "# M = model\n",
    "M = ensemble\n",
    "fn = \"ensemble.joblib\"\n",
    "dump(model, fn)\n",
    "M = model_loaded = load(fn)\n",
    "\n",
    "# Make probabilistic predictions.\n",
    "Xtest1 = np.loadtxt('/kaggle/input/higgs-spring-2024/test.csv', skiprows=1, delimiter=',')\n",
    "predictions = M.predict_proba(Xtest1)\n",
    "predictions = predictions[:,1:2] # Probability that label=1\n",
    "N = predictions.shape[0]\n",
    "assert N == 50000, \"Predictions should have lenght 50000.\"\n",
    "submission = np.hstack((np.arange(N).reshape(-1,1), predictions)) # Add Id column.\n",
    "np.savetxt(fname='submission.csv', X=submission, header='Id,Predicted', delimiter=',', comments='')\n",
    "\n",
    "# Submission can be downloaded from this Kaggle Notebook under Sessions->Data->output->/kaggle/working."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "higgs_example.ipynb",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7710627,
     "sourceId": 70482,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
